# Data-Wrangling

## Dataset

The dataset was obtained from this [link](https://drive.google.com/drive/folders/1y-or_Rba1ambWkkNzhYKtRHRwC7g0A5n). The data contains
information about ecommerce from Brazil named olist. The dataset is in .db format and it consists of 9 tables that store many information, each table has a a correlation like the image shown below.

![image](https://user-images.githubusercontent.com/109506146/218320195-c01f49fa-fa8e-488e-a3ea-23d70eb05bd6.png)

## Objective

The purpose of this study consists of two main objective, which is data cleaning and exploratory data analysis. The details of the objective is to do:

* Data Cleaning
  - Checking and filling null values
  - Checking and deleting duplicate values
  - Assigning correct data type

* Exploratory Data Analysis
  - Finding Top and Bottom 10 Categories based on number of order per category
  - Finding out the effect of price and freight value on number of order
  - Finding which categories have the most repeat ordered item
  - Explore seller response time when receiving order

The other purpose is to use python to do the objectives mentioned above and trying to show my skill in using python to do data cleaning and EDA. In this study, I'm using libraries like pandas, matplotlib.pyplot, and seaborn.

This github page only has the code for each step on the data cleaning and EDA. If you didn't come here from medium and want to read more about the data cleaning and analysis that I've done, please kindly visit my [medium page](https://medium.com/@alamkelanalubis/data-cleaning-and-analysis-on-ecommerce-data-using-python-a9af6b567ab).

Thank you for visiting, any comment or correction is highly appreciated!:)
